{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5610e874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2094\n",
      "Index(['valor', 'returns', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5',\n",
      "       'lag_10'],\n",
      "      dtype='object')\n",
      "2094\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_path =  '/home/agusitn/Documents/projects/blue-dollar-ml/data/processed/info_finally.csv'\n",
    "df = pd.read_csv(df_path, parse_dates=['fecha'], index_col='fecha')\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "print(len(df))\n",
    "\n",
    "df['returns'] = df['valor'].pct_change()\n",
    "\n",
    "lags = [1,2,3,4,5,10]\n",
    "\n",
    "for l in lags:\n",
    "    df[f\"lag_{l}\"] = df['returns'].shift(l)\n",
    "print(df.columns)\n",
    "\n",
    "\"\"\" \n",
    "Creamos una linea de tendecias en base 5/10/20 dias si la media esperada (rolling_mean ) es positiva y alta\n",
    "significa que la tendecia del el ultimo mes/semana/dias es que el dolar suba.\n",
    "\n",
    "Luego si la desviacion estandar es muy volatil quiere decir que el dolar baja y sube constantemente... es decir: \n",
    "Si la desviacion estandar (rolling_std) es alta el dolar un dia puede subir un 5% y al otro un 20% y de repente al otro baja un 19%\n",
    "Si la desviacion estandar es baja el mercado esta estable\n",
    "\"\"\"\n",
    "windows = [5,10,20]\n",
    "for w in windows:\n",
    "    df[f'rolling_mean_{w}'] = df['returns'].rolling(window=w).mean()\n",
    "    df[f'rolling_std_{w}'] = df['returns'].rolling(window=w).std()\n",
    "\n",
    "# print(len(df))\n",
    "# df.dropna(inplace=True)\n",
    "# print(len(df))\n",
    "df.to_csv('/home/agusitn/Documents/projects/blue-dollar-ml/data/processed/feature_basic.csv')\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a01d9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando RSI...\n",
      "Calculando Fechas...\n",
      "¡Listo! Archivo features_advanced.csv creado sin errores.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_rsi(series_data, periodo=14):\n",
    "    # series_data ya es la columna de precios. Calculamos directo.\n",
    "    delta = series_data.diff()\n",
    "    delta = delta.dropna() # El diff genera un NaN al principio\n",
    "\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "    # Usamos ewm (Exponential Weighted Moving)\n",
    "    avg_gain = gain.ewm(com=periodo-1, adjust=False).mean()\n",
    "    avg_loss = loss.ewm(com=periodo-1, adjust=False).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "df_path = '/home/agusitn/Documents/projects/blue-dollar-ml/data/processed/info_finally.csv'\n",
    "\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')\n",
    "df.dropna(subset=['fecha'], inplace=True)\n",
    "\n",
    "df.drop_duplicates(subset=['fecha'], keep='first', inplace=True)\n",
    "\n",
    "df.set_index('fecha', inplace=True)\n",
    "\n",
    "df['valor'] = pd.to_numeric(df['valor'], errors='coerce')\n",
    "df.dropna(subset=['valor'], inplace=True) # Borramos si falló alguno\n",
    "\n",
    "\n",
    "print(\"Calculando RSI...\")\n",
    "df['rsi'] = get_rsi(df['valor'], periodo=14)\n",
    "\n",
    "print(\"Calculando Fechas...\")\n",
    "df['day_of_week'] = df.index.dayofweek\n",
    "df['is_end_of_month'] = (df.index.day > 25).astype(int)\n",
    "\n",
    "# Limpieza final (el RSI deja los primeros 14 días vacíos)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "save_path = '/home/agusitn/Documents/projects/blue-dollar-ml/data/processed/features_advanced.csv'\n",
    "df.to_csv(save_path)\n",
    "\n",
    "print(\"¡Listo! Archivo features_advanced.csv creado sin errores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9951ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_path = '/home/agusitn/Documents/projects/blue-dollar-ml/data/processed/features_advanced.csv'\n",
    "df = pd.read_csv(df_path, parse_dates=['fecha'], index_col='fecha')\n",
    "\n",
    "colum_data_leak = [col for col in df.columns if 'rsi' in col]\n",
    "df[colum_data_leak] = df[colum_data_leak].shift(1)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['returns'] = df['valor'].pct_change()\n",
    "df['target_up'] = (df['returns'] > 0).astype(int)\n",
    "\n",
    "features = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if c not in  ['returns', 'target_up', 'valor']:\n",
    "        features.append(c)\n",
    "\n",
    "total_rows = len(df)\n",
    "train_idx = int(total_rows * 0.70)\n",
    "val_idx = int(total_rows * 0.85)\n",
    "\n",
    "x = df[features]\n",
    "y = df['target_up']\n",
    "\n",
    "x_train = x.iloc[:train_idx]\n",
    "y_train = y.iloc[:train_idx]\n",
    "\n",
    "x_val = x.iloc[train_idx:val_idx]\n",
    "y_val = y.iloc[train_idx: val_idx]\n",
    "\n",
    "x_test = x.iloc[val_idx:]\n",
    "y_test = y.iloc[val_idx:]\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "    Debemos normalizar los retornos ya que los datos tienen escalas distintas:\n",
    "        - El retorno es un número chiquito (ej. 0.01).\n",
    "        - La volatilidad puede ser otro número diferente.\n",
    "    La Regresión Logística se confunde si mezclas números grandes con chicos. El StandardScaler pone todo en la misma escala para que el modelo aprenda bien.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "predict = model.predict(x_test_scaled)\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "\n",
    "print(\"\\nResultados del Gran Desafío:\")\n",
    "print(f\"Modelo con Features Avanzados: {accuracy:.2%}\")\n",
    "print(f\"Baseline a vencer (Como Ayer): 58.68%\")\n",
    "\n",
    "if accuracy > 0.5868:\n",
    "    print(\"¡OBJETIVO CUMPLIDO! Tu modelo aprendió patrones reales.\")\n",
    "else:\n",
    "    print(\"Seguimos empatados o perdiendo. Necesitamos modelos más complejos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
